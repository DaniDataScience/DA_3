---
title: "DA3 HW3 Technical report"
author: "Gyebnar Daniel"
date: '2022 02 15 '
output:
  html_document: default
  pdf_document: default
---

# Assessment of fast growing firms

## Abstract
FastInvest, a newly established Private Equity aims to invest in companies that have a potential of growing rapidly in the next years. The goal of this project was to identify firms with such potential using the tools of prediction and classification by using logit, lasso, and random forest models. 
The goal of this technical report is to detail decisions made during the analysis.

## Data used
.
The data was used for this analysis was collected, maintained, and cleaned by Bisnode, a major
European business information company, containing financial, management and other data on all companies in the EU. The analysis focused on the range of 2010-2015

## Business case 
FastInvest aims to invest EUR 100,000 in each firm identified as fast growing. 
Based on their investment policy they purchase firms that are expected to grow by at lest 50% annually, and hold them for 5 years.

#### Definition of fast growing firms
Based on the business requirements, the definition of fast growing firms is based on the growth rate of 2 years, from 2012 to 2014, reaching at least a 50% growth in revenues annually. The two years span aims to ensure that the growth is not due to an extraordinary event, and that the fast growth can be expected to remain in the holding period of 5 years. 

In the cleaned data set used for predicting, this resulted in the following distribution:
```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width="50%", fig.cap="Histogram of CAGR", fig.align = 'center'}
library(kableExtra)
library(tidyverse)
library(dplyr)
data <- read.csv("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/data/bisnode_firms_clean.csv")


data %>% 
  group_by(fast_growth_f) %>% 
  summarise("Number of companies" = n(), "Percentage" = paste0(round(n()/(1598+12541)*100),'%')) %>% 
  kbl() %>% 
  kable_classic(full_width = F, html_font = "Cambria")


```

#### Definition of loss function
Consequentially, the loss function needed to reflect the investment rationale:

- An investment of EUR 100,000 at 50% annual growth will lead to EUR 800,000 USD, a profit of USD 700,000. This is a conservative estimation, as the average of growth rates for companies labelled as "fast growing" is 150% based on the cleaned Bisnode dataset
- This leads to a False Negative decision resulting in EUR 700,000 USD loss (cost of profit lost from not investing in the company)
- While a False Positive decision results in the loss of the EUR 100,000 invested (assuming that the investment of the PE would be stuck)

Based on the business rationale, I set the cost function as FN/FP = 7

## Data cleaning process
The data originally had c.290,000 observations on c.46,000 firms from 2005 to 2016, with 48 variables describing information on balance sheet, assets, liabilities, profit and loss, management. In the end of data cleaning I ended up with 14,139 observations (each a firm from 2012) and 116 variables. The process of feature engineering and observation selection is described in following subchapters.

#### Selecting observations
I filtered the data for the 2010-2015 period, and included firms with a revenue between EUR 1,000 - 1,000,000 to capture SMEs. I excluded observations of firms that are no longer active, and also restricted the firms to 2012 (base year of prediction), and below CAGR of 3000 (to exclude potential mistakes and unprecedented events of growth that are not likely to be repeated in case of a purchase)

#### Adding new variables
I added the CAGR of 2012-2014, and the target variable to predict: the fast-growth binary variable, based on the 50% CAGR threshold identified previously.  

I also added explanatory variables, such as log sales, previous CAGRs (2010-'11 and 2011-'12), foreign management variable and CEO age. I included ratios for key financials by dividing all balance sheet elements with totalassets, and similarly with profit and loss statement elements. 

### Droping variables, Imputation  corrections
I dropped variables that had too many missing values (above 15,000 in raw dataset). I used winsorization to correct values for certain items that are not possible based on domain knowledge, and flagged these events sheet (e.g. negative assets, sales), and I created category variables and created factors.

In the end, I had the following distributions:
```{r, echo=FALSE,message=F, warning=F, out.width="50%", fig.cap="Histogram of CAGR", fig.align = 'center'}
library(kableExtra)
knitr::include_graphics("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/plot_cagr_hist.png")
```

```{r, echo=FALSE, out.width="50%", fig.cap="Histogram of log sales", fig.align = 'center'}
library(kableExtra)
knitr::include_graphics("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/plot_cagr_hist.png")
```

The resulf of winsorisation of log sales:
```{r, echo=FALSE, out.width="50%", fig.cap="Winsorisation log sales difference", fig.align = 'center'}
library(kableExtra)
knitr::include_graphics("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/winsorisation.png")
```
## Modeling process
I created 3 types of models: logit, LASSO and Random Forest. First I predicted the probabilities of firm being fast-growing or not, using 5-fold cross-validation on the training set. I selected preferred models, and used a loss function and a threshold to categorize the prediction results into fast growing / not fast growing. I evaluated the model with the smallest loss on the holdout set as a final result, and created the confusion matrix for evaluation. 

#### Creating models
I grouped variables according to their meaning, and created formulas for the models based on that:

- Raw variables are key variables such as main profit and loss and balance sheet elements
- Engine variables 1 are other profit and loss and balance sheet elements
- Engine variables 2 are quadratic transformation of  key variables (profit and loss, income before tax, extra profit and loss)
- Engine variables 3 are flags of engine 2 variables, where modification was needed (winsorisation, imptation)
- D1 are variables measuring change of sales
- HR are data about management such as age and gender of CEO or average labor number
- Firm are : properties of the firms like age of the company, region, etc.
- Interactions 1 and 2 are interactions of variables

From these groups, I created the following models:
```{r, echo=F, message=F, warning=F, fig.cap="Models used"}
models <- data.frame(row.names = c("X1 model", "X2 model", "X3 model", "X4 model", "X5 model", "LASSO", "Random Forest"))
models$Variables[1] <- "Log sales + Log sales^2 + Change in Sales + Profit and loss + Industry"
models$Variables[2] <- "X1 + Fixed assets + Equity + Current liabilities (and flags) + Age + Foreign management"
models$Variables[3] <- "Log sales + Log sales^2 + Firm + Engine variables 1 + D1"
models$Variables[4] <- "X3 + Engine variables 2 + Engine variables 3 + HR"
models$Variables[5] <- "X4 + Interactions 1 and 2"
models$Variables[6] <- "X5"
models$Variables[7] <- "sales_mil + d1_sales_mil_log + rawvars + hr + firm + qualityvars"
models %>% 
  kbl() %>% 
  kable_classic(full_width = F, html_font = "Cambria")
```

I created a holdout set from the 20% of the data. The total set, the holdout set and the train set as well had a c.11% ratio of fast growing firms. The train data was used for a 5-fold cross validation.

## Prediction 
The best model was X3 logit model based on giving the largest AUC result. 

#### Logit models
I evaluated the 5 logit models based on the cross-validated RMSE and AUC. Model X4 provided the best results in term of AUC, but it is much more complex than X3, which is my preferred model. 

```{r, echo=F, message=F, warning=F, fig.cap="Summary of logit results"}

library(kableExtra)
logit_summary1<- read.csv("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/exp_logit_summary1.csv")

logit_summary1 %>% 
  slice(1:5) %>% 
  kbl() %>% 
  kable_classic(full_width = F, html_font = "Cambria")
```

#### LASSO model
The LASSO model was based on the most complex X5 formula with all variable. Lasso shrank the number of coefficients from 85 to 70, and resulted in a better RMSE, but inferior AUC compared to X3
```{r, echo=F, message=F, warning=F, fig.cap="Summary of logit results"}
logit_summary1 %>% 
  slice(3,6) %>% 
  kbl() %>% 
  kable_classic(full_width = F, html_font = "Cambria")
```

#### Random Forest
Random forest was based on using unchanged variables mostly. This is due to the random Forest "figuring out" functional forms by splits and conditional means, so adding higher orders and modified functional forms was not necessary.

The RF was run with growing 500 trees, with 10 and 15 as the minimum number of observations  and 5, 6 or 7 variables in each split. The Random Forest performed slightly worse than the X3 model in terms os AUS but gave a slightly better RMSE.
```{r, echO=FALSE, message=F, warning=F}
library(kableExtra)
exp_rf_summary<- read.csv("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/exp_rf_summary.csv")
exp_rf_summary %>% 
  slice(c(3,7)) %>% 
  kbl() %>% 
  kable_classic(full_width = F, html_font = "Cambria")
```

#### Model results
Before finding the best thresholds for prediction, I created calibration and the ROC plot for the best model so far, the X3 Logit model. The calibration curve show the model performance. We can see that for values below 0.4, the model did a pretty good job, however, above 0.4 the model was too conservative, it predicted lower values (e.g. 0.5 instead of 0.7).

```{r, echo=FALSE,message=F, warning=F, out.width="50%", fig.cap="Calibration plot for X3", fig.align = 'center'}
library(kableExtra)
knitr::include_graphics("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/plot_calibration.png")

```

Below I included the ROC plot and the area under the curve for X3, showing the AUC colored. From these graphs we can see the effects of choosing a higher/lower threshold on FN and FP values.
```{r, echo=FALSE, out.width="50%", fig.cap="ROC plot for X3", fig.align = 'center'}
library(kableExtra)
knitr::include_graphics("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/plot_ROC.png")

```

## Classification
#### Setting treshold
In order to classify the predictions into categories of fast growth / not fast growth, I selected a threshold. I used the loss function explained under the chapter "Business Case", with cost=7. Based on the formula the optimal classification threshold would be 1/(1+7) = 0.125, but also used an algorithm to calculate optimal thresholds (0.128 for Random Forest). The results can be found below:

```{r, message=F, warning=F, echo=FALSE, out.width="50%", fig.cap="CV thresholds and Expected loss", fig.align = 'center'}
library(kableExtra)
summary_results<- read.csv("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/exp_summary_results.csv")

summary_results %>% 
  kbl() %>% 
  kable_classic(full_width = F, html_font = "Cambria")
```
#### Model choice and evaluation
Based table expected loss in the table above, the random forest is the best model to use due to lowest expected losses, followed by X3 Logit model, and then LASSO. Interestingly, ordering the models based on AUC would yield a different list, with X3 Logit being the best, followed by LASSO.

This is even smaller than what I got for the train data. Below is the confusion table for the model, showing the choices made by the model, in comparison to the actual values. Based on this the model performance is the following:

```{r, message=F, warning=F}
library(kableExtra)
exp_cm_rf.csv<- read.csv("https://raw.githubusercontent.com/DaniDataScience/DA_3/main/DA3/Assignment_3/exp_cm_rf.csv")
exp_cm_rf.csv %>% 
  kbl() %>% 
  kable_classic(full_width = F, html_font = "Cambria")
Accuracy=(228+1786)/(228+727+86+1786)
Sensitivity = 228 / (228 + 86)
Specificity = 1786 / (1786 + 727)
```

Accuracy is 71.2%
Sensitivity is 72.6%
Specificity is 71.1%
Correctly predicted positive 23.9%

This yeilds the following loss:

- We wrongly invest 0.1 m in 727 firms that are not fast growing, loosing EUR 72.7 m
- We do not invest in 86 firms that are fast growing, loosing 86x0.7 = EUR 60.2 m
- That is a total loss of USD 132.9 m

To explain these results:
- If we would guess all 314 fast growing firms correctly we would profit 0.7x314 = USD 219.8 m 
- Based on the CM, we would gain 228x0.7 and loose 727x0.1 , resulting in a profit 159.6-72.2= USD 87 m
- The total loss compared to the best solution is 219.8 - 87 = 132.9 m , same as above.

#### Summary
The task was to select fast growing firms, defined as firms growing at least 50% annually. For this, I built Logit, LASSO, and Random Forest models sing the Bisnode dataset on firms. I defined the loss function with False Negatives being 7 times worse as False Positives, based on the business case of Private Equity client. The final model I chose was the Random Forest.  The accuracy of the model was 71% meaning that is classified 71% of the firms into the correct categoryand identified not fast growing firms 71.1% correctly, while from the actual fast growing ones it predicted 72.6% right. 

From the firms the model predicted to be fast growing 24% actually turned out to be fast growing. This is more than twice as high as the occurance of fast growing firms in a random sample (11%)


